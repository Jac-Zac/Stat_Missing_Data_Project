---
title: "Missing Data Analysis: Methods and Experiments"
author: "Jacopo Zacchigna, Devid Rosa, Cristiano Baldassi, Ludovica Bianchi"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    # toc_float: false
    code_fold: hide # Hidden by default unless specified otherwise
    df_print: paged
    highlight: tango
    theme: flatly
    number_sections: true
    toc_collapsible: true  # Enable collapsible TOC
editor_options:
  markdown:
    wrap: 72
---

```{r, echo=F, class.source = 'fold-show'}
library(here)

# Load utilities
source(here("src", "setup.R"))

# Define the child RMarkdown file path
child <- here("notebooks", "dataset_analysis", "synthetic_data_analysis.Rmd")
```

```{r, child = here("notebooks", "dataset_analysis", "synthetic_data_analysis.Rmd"), cache = TRUE}
# Run the file which does data analyses even if not knitted by runned manually
rmarkdown::render(child)
```

# Imputation Methods

The following imputation methods are tested on both the MCAR and MAR datasets. A regression model is fit on the imputed dataset, and the results are summarized.

## 1. Listâ€‘wise (Case) Deletion

List-wise deletion removes any case with missing values from analysis and is the default method in many statistical software tools. It works well when data is large and missing completely at random (MCAR). However, if these conditions are not met, it can lead to bias and loss of important information, making it a less suitable approach.

```{r}
listwise_deletion_data <- listwise_deletion(data.MAR.uni)
```
## 2. Pairwise Deletion

Pairwise deletion minimizes information loss compared to list-wise deletion by only removing data points when necessary to check if missing values are truly missing. It produces lower bias for data missing completely at random (MCAR) or missing at random (MAR).

```{r}
pairwise_deletion_data <- pairwise_deletion(data.MAR.uni)
```

## 3. Simple Imputation

Simple imputation replaces missing values using the mean, median, or mode of non-missing data, offering simplicity and ease of use. However, it can introduce bias or unrealistic results, especially in high-dimensional or large-scale data sets, making it unsuitable for handling big data effectively.

#### Mean Imputation

```{r}
# Evaluate imputation method using mean imputation
mean_imputation_data <- simple_imputation(data.MAR.uni, "mean")
mean_metrics <- compare_distributions(synthetic_data, mean_imputation_data)
```

#### Median Imputation

```{r}
# Evaluate imputation method using median imputation
median_imputation_data <- simple_imputation(data.MAR.uni, "median")
median_metrics <- compare_distributions(synthetic_data, median_imputation_data)
```
## 4. Regression Imputation
> NOTE: In the final version this is the idea (fit a model correctly here we simply used stepAIC) for each of the inputation techniqeus were this is needed

Regression imputation replaces missing values using predictions from a regression model built on complete data, preserving sample size and assuming data is missing at random (MAR). It includes single and multivariate regression methods, depending on the number of missing variables. 

```{r, class.source = 'fold-show'}
#' Regression Imputation
#' @param data Data frame with missing values
#' @param noise Logical; if TRUE, adds noise to the imputed values (default = FALSE)
#' @return Data frame with missing values imputed using regression
regression_imputation <- function(data, noise = FALSE) {
  for (col in names(data)) {
    if (any(is.na(data[[col]])) && is.numeric(data[[col]])) {
      complete_data <- data[complete.cases(data), ]
      incomplete_rows <- which(is.na(data[[col]]))
      predictors <- setdiff(names(data), col)
      model <- lm(as.formula(paste(col, "~ .")), data = complete_data)
      predictions <- predict(model, newdata = data[incomplete_rows, predictors, drop = FALSE])

      if (noise) {
        # Calculate residuals and their standard deviation
        residuals <- model$residuals
        residual_sd <- sd(residuals, na.rm = TRUE)

        # Add random noise to the predictions (scaled by residual_sd)
        noise_values <- rnorm(length(predictions), mean = 0, sd = residual_sd)
        predictions <- predictions + noise_values
      }

      data[[col]][incomplete_rows] <- predictions
    }
  }
  return(data)
}

# Perform imputation on MCAR and MAR datasets
regression_imputation_data <- regression_imputation(data.MAR.uni)
regression_metrics <- compare_distributions(synthetic_data, regression_imputation_data)
```


## 5. Hot-deck Imputation

Hot-deck imputation replaces missing values by selecting a donor from similar cases with complete data, either randomly or based on the closest match. It is widely used because it preserves data structure, reduces bias, and avoids model dependency. However, it lacks a robust theoretical foundation compared to other imputation techniques. 

```{r}
# Evaluate imputation method using hot-deck imputation
hotdeck_imputation_data <- hot_deck_imputation(data.MAR.uni)
hotdeck_metrics <- compare_distributions(synthetic_data, hotdeck_imputation_data)
```

## 6. Expectation-Maximization (EM)

The expectation-maximization (EM) algorithm iteratively handles missing data using an "impute, estimate, and iterate" process until convergence. It alternates between the expectation step, estimating missing values based on observed data, and the maximization step, optimizing the likelihood of the complete data. It requires costly matrix computations.

```{r}
# Evaluate imputation method using EM imputation
em_imputation_data <- em_imputation(data.MAR.uni)
em_metrics <- compare_distributions(synthetic_data, em_imputation_data)
```

## 7. Multiple Imputation

Multiple imputation addresses missing data by generating multiple complete datasets using observed data distributions to estimate missing values, reflecting uncertainty. Analysis is performed on each dataset, and results are combined into a single estimate. This technique overcomes single imputation limitations, reducing bias and providing more reliable results. 

## 8. GAM Imputation

GAM-based imputation leverages Generalized Additive Models to handle missing data, allowing for flexible modeling of relationships between variables. This technique is particularly effective when the relationship between predictors and the target variable is non-linear.

```{r}
# Evaluate imputation method using GAM-based imputation
gam_imputation_data <- gam_based_imputation(data.MAR.uni)
gam_metrics <- compare_distributions(synthetic_data, gam_imputation_data)
```

## Imputation methods inspired by ML

> Evaluate which of those one makes sense to actually test

### Decision tree / Random Forests

Decision tree imputation builds a predictive model for each variable with missing data by constructing a decision tree where branches represent decisions based on predictor variables, and leaves represent the predicted values. This method can handle both categorical and numerical data while capturing complex interactions and patterns in the data.

```{r}
# Evaluate imputation method using tree-based (Random Forest) imputation
forest_imputation_data <- tree_based_imputation(data.MAR.uni)
forest_metrics <- compare_distributions(synthetic_data, forest_imputation_data)
```


# Results and Discussion

## Performance metrics for the Prediction

- **Mean Absolute Error (MAE)**

    MAE measures the average difference between imputed values and true values defined as:
    
    $$
    MAE = \frac{1}{m}\sum_{i=1}^m|y_i - \hat{y}_i|
    $$

- **Mean Squared Error (MSE)**
    
    While MSE is equal to the sum of variance and squared predicted missing value as in the following equation:
    
    $$
    MSE = \frac{1}{m}\sum_{i=1}^m(y_i - \hat{y}_i)^2
    $$

- **Root Mean Square Error (RMSE)**

    RMSE computes the difference in imputed values and actual values as follows:
  
    $$
    RMSE = \sqrt{MSE}
    $$
    
- **Area under the curve (AUC)**

    AUC is the representation of the degree or measure of separability and is used as a summary of the Root Receiver Operator Characteristic (ROC) curve, which is curve is a visualisation graph representing imputation performance [143]. The AUC is represented by the true positive rate (TPR) and the false positive rate (FPR). Where the TPR is the proportion of correctly imputed positives of all positives and the TPR is the proportion of all negatives that are wrongly imputed as positives [144]. The true positive rate and the false positive rate are defined as:
    
    $$
    TPR = \frac{TP}{TP + FN} \tag{21}
    $$
    
    $$
    FPR = \frac{FP}{FP + TN} \tag{22}
    $$
    
#### Function implementation for different performance metrics
> They are defined inside metrics
    
```{r}
# library(pROC)
# roc_obj <- roc(actual, predicted)
# auc_value <- auc(roc_obj)
```

```{r}
knitr::opts_chunk$set(eval = FALSE, echo = FALSE)
```

### Test linear model for each Imputation method

```{r}
# List of precomputed imputed datasets
imputed_datasets <- list(
  "Original Dataset" = synthetic_data, # Do it again for the original dataset
  "Listwise Deletion" = listwise_deletion_data,
  "Pairwise Deletion" = pairwise_deletion_data,
  "Mean Imputation" = mean_imputation_data,
  "Median Imputation" = median_imputation_data,
  "Regression Imputation" = regression_imputation_data,
  "Hot-deck Imputation" = hotdeck_imputation_data,
  "EM Imputation" = em_imputation_data,
  "GAM Imputation" = gam_imputation_data,
  "Random Forest Imputation" = forest_imputation_data
)

# Function to calculate RMSE and MAE for each imputed dataset
calculate_metrics <- function(imputed_data) {
  metrics <- evaluate_model_performance(imputed_data, test_data)
  return(c(metrics$rmse, metrics$mae))
}

# Apply the function to all imputed datasets and store results
metrics_results <- do.call(rbind, lapply(names(imputed_datasets), function(method) {
  metrics <- calculate_metrics(imputed_datasets[[method]])
  data.frame(
    Method = method,
    Metric = c("RMSE", "MAE"),
    Value = metrics,
    Highlight = ifelse(method == "Original Dataset", "Highlight", "Other"),
    stringsAsFactors = FALSE
  )
}))
```

#### Comparing Predictions (RMSE and MAE) of the linear model for each method
> The original dataset is highlighted in red.

Here we simply made a simple linear model with all of the covariate (knowing our synthetic dataset). To compare the RMSE and MAE when dealing with different inputated dataset.

```{r, echo = FALSE}
# Define the function to create the plot with horizontal bars
create_bar_plot <- function(metric_name) {
  # Get the maximum value to set appropriate limits
  max_value <- max(metrics_results[metrics_results$Metric == metric_name,]$Value)
  
  ggplot(metrics_results[metrics_results$Metric == metric_name,], 
         aes(x = reorder(Method, Value), y = Value, fill = Highlight)) +
    geom_bar(stat = "identity") +
    geom_text(aes(label = sprintf("%.3f", Value)), hjust = -0.5) +
    labs(
      title = paste(metric_name, "Across Imputation Methods"),
      x = "Imputation Method",
      y = paste(metric_name, "Value")
    ) +
    scale_fill_manual(
      values = c("Highlight" = red_nord, "Other" = blue_nord),
      guide = "none"
    ) +
    theme_minimal() +
    coord_flip(xlim = NULL, ylim = c(0, max_value * 1.2)) +  # Add 20% extra space on the right
    theme(
      plot.margin = unit(c(1, 1, 1, 1), "pt")  # top, right, bottom, left margins
    )
}

# Create and display the plots
mae_plot <- create_bar_plot("MAE")
rmse_plot <- create_bar_plot("RMSE")

# To display the plots
mae_plot
rmse_plot
```

## Computational Performance

.. Some small note on this

