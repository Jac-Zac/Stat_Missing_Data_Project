---
title: "Case Study"
author: "Jacopo Zacchigna, Devid Rosa, Cristiano Baldassi, Ludovica Bianchi"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    toc: true 
    toc_depth: 3
    toc_float: true
    # toc_float: false
    code_fold: hide # Hidden by default unless specified otherwise
    df_print: paged
    highlight: tango
    theme: flatly
    number_sections: true
    toc_collapsible: true  # Enable collapsible TOC
---

```{r librerie, echo=TRUE, results='hide', warning=FALSE, include = F}
# Load utilities
suppressMessages(library(here))

# Load utilities
source(here("src", "setup.R"))
```


```{r import data, echo=FALSE, results='hide', warning=FALSE}
# We work with the modified version, and we set the col names by looking at the names file
auto_mpg <- read.table("auto-mpg.data", header = FALSE, sep = "")

# Assign column names based on the attribute information provided
colnames(auto_mpg) <- c("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "car_name")

# Define the color pallet
nord_colors= c("#5e81ac", "#bf616a", "#a3be8c", "#d08770", "#ebcb8b", "#b48ead")
```

# Introduction
In this analysis, we aim to construct a linear regression model for the "auto-mpg" dataset, which tracks various technical information about car models manufactured in the 1970s and 1980s. The response variable will be mpg (miles per gallon).

First, we examine the variables and observations in the dataset:

```{r info, echo=FALSE}
str(auto_mpg)
summary(auto_mpg)
```

There are 9 variables with a total of 398 observations.

-mpg: A continuous variable indicating the gallons of fuel used to travel one mile.
- cylinders: A discrete quantitative variable indicating the number of engine cylinders (to be treated as a factor).
- displacement: A continuous variable indicating engine displacement.
- horsepower: A character variable indicating the horsepower of the car (to be treated as a continuous quantitative variable).
- weight: A continuous variable indicating the car's weight.
- acceleration: A continuous variable indicating the car's acceleration.
- model_year: An integer variable indicating the year the car model was produced.
- origin: A categorical variable indicating the continent of the car manufacturer (1: America, 2: Europe, 3: Asia).
- car_name: A qualitative variable indicating the manufacturer and model name of the car.

## Data Processing
Before building our model, we need to make the data usable. We observe anomalies in the dataset variables, so we clean the data when possible. We also assign the correct data types to variables and create two new variables: cut_model_year and car_brand.

- cut_model_year: A categorical variable dividing production years into the classes 70-73, 74-76, 77-79, and 80-82.
- car_brand: A categorical variable that tracks only the car's manufacturer.

```{r preprocessing, warning=FALSE, echo = F}

# Convert horsepower as numeric
auto_mpg$horsepower <- as.numeric(auto_mpg$horsepower)

# Remove rows with missing values
auto_mpg <- na.omit(auto_mpg)

# Convert 'cylinders' and 'origin' to factors
auto_mpg$cylinders <- factor(auto_mpg$cylinders)
auto_mpg$origin <- factor(auto_mpg$origin) 

# Can be interpreted as a categorical variable but it is rectilinear
# split the model_year variable into categories based on the breaks
auto_mpg$cut_model_year <- cut(auto_mpg$model_year, breaks = c(69, 73, 76, 79, 82), labels = c("70-73", "74-76", "77-79", "80-82"))
auto_mpg$cut_model_year <- factor(auto_mpg$cut_model_year)

# Split car names by manufacturer
auto_mpg$car_brand <- str_split(auto_mpg$car_name, pattern = " ", simplify = TRUE)[, 1]

# Convert car name column to a factor
auto_mpg$car_brand <- as.factor(auto_mpg$car_brand)

# read as characters
auto_mpg$car_brand <- as.character(auto_mpg$car_brand)

# Fix mispelled names
auto_mpg$car_brand[auto_mpg$car_brand == "chevroelt"] <- "chevrolet"
auto_mpg$car_brand[auto_mpg$car_brand == "chevy"] <- "chevrolet"
auto_mpg$car_brand[auto_mpg$car_brand == "hi"] <- NA
auto_mpg$car_brand[auto_mpg$car_brand == "maxda"] <- "mazda"
auto_mpg$car_brand[auto_mpg$car_brand == "mercedes-benz"] <- "mercedes"
auto_mpg$car_brand[auto_mpg$car_brand == "toyouta"] <- "toyota"
auto_mpg$car_brand[auto_mpg$car_brand == "vokswagen"] <- "volkswagen"

# I think vw is for volkswagen
auto_mpg$car_brand[auto_mpg$car_brand == "vw"] <- "volkswagen"

#capri è un modello di ford
auto_mpg$car_brand[auto_mpg$car_brand == "capri"] <- "ford"

# Convert car names to factor after that
auto_mpg$car_brand <- as.factor(auto_mpg$car_brand)

# Drop the car name
auto_mpg <- subset(auto_mpg, select = -car_name)
auto_mpg <- subset(auto_mpg, select = -model_year)

auto_mpg <- na.omit(auto_mpg)#aggiunto per "hi"<-NA

# Count missing values in each column [mi sa che lo toglierò ~D]
#missing_values <- colSums(is.na(auto_mpg))
#print("I valori mancanti per le relative colonne sono: ")
#print(missing_values)

```


```{r summury post preprocessing, echo=FALSE}
str(auto_mpg)
summary(auto_mpg)
```

After these steps, the dataset now contains 9 variables and 391 observations:

- mpg: Continuous, indicating fuel consumption per mile.
- cylinders: Discrete, indicating the number of cylinders, categorized into 5 levels: 3, 4, 5, 6, 8.
- displacement: Continuous, indicating engine displacement.
- horsepower: Continuous, indicating car horsepower.
- weight: Continuous, indicating car weight.
- acceleration: Continuous, providing a parameter for the car's acceleration.
- origin: Categorical, indicating the continent of origin (1: America, 2: Europe, 3: Asia).
- cut_model_year: Categorical, dividing production years into the classes 70-73, 74-76, 77-79, and 80-82.
- car_brand: Categorical, tracking the car's manufacturer.

Some variables have differences in the summary statistics due to the removal of elements with null values.

## Exploratory Data Analysis

### Continuous Variables

First, we visualize the correlation matrix of the continuous variables:

```{r correlation matrix, echo=FALSE}

# Exclude factor variables
non_factor_variables = auto_mpg[, sapply(auto_mpg, function(x) !is.factor(x))]
cor_matrix <- cor(non_factor_variables)

# Plot the correlation matrix with different upper and lower
corrplot.mixed(cor_matrix, 
    lower="number", 
    upper ="ellipse",
    addgrid.col = "gray",
    tl.col = "black",
    tl.cex = 0.7,
    lower.col = colorRampPalette(c(nord_colors[2], "white", nord_colors[1]))(100),
    upper.col = colorRampPalette(c(nord_colors[2], "white", nord_colors[1]))(100)
)
```

We observe significant positive and negative correlations. Specifically, acceleration has the weakest correlation with other variables, ranging from -0.69 to 0.42. Variables like weight, horsepower, and displacement are strongly correlated with each other, which is logical since higher displacement often implies more horsepower, and heavier cars require more powerful engines.

More powerful engines also tend to consume more fuel, which aligns with expectations.

#### Scatterplots with mpg as the Response Variable

```{r, echo = FALSE}
create_plot <- function(data, x_var, x_label, title, color) {
  ggplot(data = data, mapping = aes(!!sym(x_var), log(mpg))) +
    geom_point(color = color) +
    xlab(x_label) +
    ylab("Mpg") +
    theme_bw() +
    ggtitle(title)
}

variables <- list(
  list(var = "displacement", label = "Cilindrata", title = "Scatterplot Cilindrata-Mpg", color = nord_colors[1]),
  list(var = "horsepower", label = "Cavalli-potenza", title = "Scatterplot Cavalli-Mpg", color = nord_colors[2]),
  list(var = "weight", label = "Peso", title = "Scatterplot Peso-Mpg", color = nord_colors[3]),
  list(var = "acceleration", label = "Accelerazione", title = "Scatterplot Accelerazione-Mpg", color = nord_colors[4])
)

plots <- lapply(variables, function(x) create_plot(auto_mpg, x$var, x$label, x$title, x$color))

plot_grid(plotlist = plots)

```

Scatterplots show clear patterns for the first three variables. The positive correlation between acceleration and mpg is less obvious because it has a lower absolute value.

#### Distribution of Continuous Variables


```{r histograms continues, echo=FALSE}
create_histogram <- function(data, var, label, title, color) {
  ggplot(data, mapping = aes(!!sym(var), fill = !!sym(color))) +
    geom_histogram(aes(y = after_stat(density)), color = "black", linewidth = 0.3, alpha = 0.6, fill = color, bins = 25) +
    geom_density(color = "black", linewidth = 0.3, fill = color, alpha = 0.6) +
    labs(x = label, y = "Densità", title = title) +
    theme_bw()
}

variables <- list(
  list(var = "displacement", label = "Cilindrata", title = "Istogramma Cilindrata", color = nord_colors[1]),
  list(var = "horsepower", label = "Cavalli-potenza", title = "Istogramma Cavalli", color = nord_colors[2]),
  list(var = "weight", label = "Peso", title = "Istogramma Peso", color = nord_colors[3]),
  list(var = "acceleration", label = "Accelerazione", title = "Istogramma Accelerazione", color = nord_colors[4])
)

histograms <- lapply(variables, function(x) create_histogram(auto_mpg, x$var, x$label, x$title, x$color))

plot_grid(plotlist = histograms)
```

The histogram of displacement shows a positively skewed distribution with a peak around 100. The distributions of weight and horsepower are also positively skewed, with heavier right tails. The acceleration variable shows a perfectly symmetrical distribution with mean, mode, and median around 15.

#### Distribution of mpg

```{r, echo=FALSE}
create_histogram(auto_mpg, "mpg", "Mpg", "Istogramma Miglia per Gallone", nord_colors[6])
```

The histogram shows that mpg has a positively skewed distribution with a long right tail. This is more evident when a kernel density curve is added to the histogram, suggesting that transformations may be necessary.

### Categorical Variables

We analyze categorical variables in relation to mpg using boxplots. For the high number of categories in car_brand, we use a bar plot instead.

```{r plots for categorical variables, echo=FALSE}
# Create a base plot with common code

plots <- list(
    ## Boxplots
    ggplot(auto_mpg, aes(x = cylinders, y = mpg)) + 
    geom_boxplot(fill = nord_colors[1], alpha = 0.3) +  
    labs(title = "Boxplot of mpg by cylinders",
        x = "Cylinders", y = "Mpg") +
        theme_bw(),

    ggplot(auto_mpg, aes(x = origin, y = mpg)) + 
    geom_boxplot(fill = nord_colors[2], alpha = 0.3) +  
    labs(title = "Boxplot of mpg by origin",
        x = "Origin", y = "Mpg") + 
        theme_bw(),
    
    ggplot(auto_mpg, aes(x = cut_model_year, y = mpg)) + 
    geom_boxplot(fill = nord_colors[3], alpha = 0.3) +  
    labs(title = "Boxplot of mpg by model_year",
        x = "Model Year categories", y = "Mpg") + 
        theme_bw(),
    
    ggplot(auto_mpg, aes(x = car_brand, y = mpg)) +
        stat_summary(fun = mean, geom = "col", fill = nord_colors[4]) +
        scale_fill_gradient2(low = nord_colors[1],
        high = nord_colors[2], mid = "white", midpoint = 0) +
        theme_bw() +
        theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
        labs(title = "Barplot of mean mpg by car_brand",
             x = "Car brand", y = "Mean mpg")
)

grid.arrange(grobs = plots, ncol = 2)
```

The number of cylinders slightly influences mpg. We notice that 4-cylinder engines appear to be the most efficient (in fact, mid-to-high range compact cars generally use this type of engine, where low fuel consumption is a key requirement). Conversely, 8-cylinder engines are the least efficient in terms of fuel consumption (as 8-cylinder engines, typically V8s, are characteristic of supercars or American muscle cars).

The country where the car manufacturer is based also seems to impact fuel consumption. American manufacturers tend to produce cars with higher fuel consumption, while Asian manufacturers perform slightly better than European ones.

The year of production shows a positive trend regarding fuel efficiency as the years progress. This could be attributed to technological advancements enabling the production of more fuel-efficient cars or to the oil crises of the 1970s, which may have pushed manufacturers in this direction.

Finally, regarding the car manufacturer, it is difficult to identify very significant patterns. The only notable observation is that some brands, like Nissan, for example, have a much higher average miles-per-gallon compared to brands like Chrysler (noting that the former is an Asian brand, while the latter is American).

### Histograms and Density Curves

#### Histogram of mpg by Origin

```{r historgrams origin, echo=FALSE}
## Histogram
ggplot(auto_mpg, aes(x = mpg, fill=origin )) +
    # Plot the histogram with density instead of counts on the y-axis
    geom_histogram(aes(y = after_stat(density)),
    color = "black", linewidth=0.3, alpha = 0.5, bins=25) + 
    facet_wrap(~ origin) + # Create facets for each smoker category
    geom_density(aes(colour = factor(displacement)), lwd = 0.25, colour = "black") +
    scale_fill_manual(values = alpha(nord_colors,0.6)) + # Customize the fill color with transparency
    scale_colour_manual(values = alpha(nord_colors,1)) + # Customize the line color with full opacity
    labs(title = NULL , x = NULL, y = NULL) +  # Add legend titles and labels
    theme_bw() +
    theme(legend.position = "none", axis.text = element_text(size = 6)) # Hide the color labels
```

The graphs show unimodal curves with differing frequency peaks and averages based on the continent of origin:

- American Cars: Average 20 mpg, mode 13 mpg.
- European Cars: Average 27 mpg, mode 24 mpg.
- Asian Cars: Average 30 mpg, mode 32 mpg.

This confirms that American cars generally consume more fuel, followed by European cars, with Asian cars being the most fuel-efficient.

#### Histogram of mpg by Number of Cylinders

```{r historgrams cylinders, echo=FALSE}
## Histogram
ggplot(auto_mpg, aes(x = mpg, fill=cylinders )) +
    # Plot the histogram with density instead of counts on the y-axis
    geom_histogram(aes(y = after_stat(density)),
    color = "black", linewidth=0.3, alpha = 0.5, bins=15) + 
    facet_grid(~ cylinders) + # Create facets for each smoker category
    geom_density(aes(colour = factor(displacement)), lwd = 0.25, colour = "black") +
    scale_fill_manual(values = alpha(nord_colors,0.6)) + # Customize the fill color with transparency
    scale_colour_manual(values = alpha(nord_colors,1)) + # Customize the line color with full opacity
    labs(title = NULL, x = NULL, y = NULL) +  # Add legend titles and labels
    theme_bw() +
    theme(legend.position = "none", axis.text = element_text(size = 6)) # Hide the color labels
```

The distributions are similar across categories, with high peaks followed by heavier right tails. This suggests that the number of cylinders is not a major factor in explaining mpg. However, cars with more cylinders tend to achieve fewer miles per gallon. Data on 5-cylinder cars is limited, making conclusions difficult.

#### Histogram of mpg by Production Year

```{r historgrams model year, echo=FALSE}
## Histogram
ggplot(auto_mpg, aes(x = mpg, fill=cut_model_year )) +
    # Plot the histogram with density instead of counts on the y-axis
    geom_histogram(aes(y = after_stat(density)),
    color = "black", linewidth=0.3, alpha = 0.5, bins=20) + 
    facet_wrap(~ cut_model_year) + # Create facets for each smoker category
    geom_density(aes(colour = factor(displacement)), lwd = 0.25, colour = "black") +
    scale_fill_manual(values = alpha(nord_colors,0.6)) + # Customize the fill color with transparency
    scale_colour_manual(values = alpha(nord_colors,1)) + # Customize the line color with full opacity
    labs(title = NULL, x = NULL, y = NULL) +  # Add legend titles and labels
    theme_bw() +
    theme(legend.position = "none", axis.text = element_text(size = 6),
          plot.title = element_text(size = 14)) # Hide the color labels
```

Production year initially appears to have little influence, but there is a marked change in distribution patterns for cars from the 1980s, particularly compared to those from the early 1970s.



## Linear Regression Model

### Bivariate Model

We identify the most suitable explanatory variable for a bivariate linear regression model. Weight emerges as the strongest candidate, supported by statistical tests and visual inspection.

The linear model using weight has:

An intercept of 46.2 (caution is needed as it is unrealistic to consider a car with zero weight).
A negative slope of -0.008, meaning that for every additional pound of weight, mpg decreases by 0.008.
The F-test indicates that weight is a significant variable (p-value close to 0). Other variables like displacement, horsepower, origin, and cut_model_year also show promise for a multivariate model.

Residual analysis reveals issues with homoscedasticity (residuals are unevenly dispersed) and some deviations from normality. However, the model follows a nearly linear form.

Visualizing the Linear Model
We analyze the interaction between weight, the number of cylinders, mpg, and the origin of manufacture. Heavier cars, typically produced by American manufacturers, consume more fuel, aligning with their preference for larger, V8-engine vehicles. European and Asian manufacturers focus on more minimalistic designs.

Given the strong relationship between weight, origin, and cylinders, adding the latter two variables may not significantly enhance the model.

Multivariate Model
We construct a multivariate model, testing various combinations of variables. Key findings:

Some models show that all variables significantly contribute to explaining mpg.
Others indicate that origin is not statistically significant (high p-value).
Adjusted R-squared values improve significantly compared to the bivariate model, increasing by nearly 20 percentage points.

Model Selection Using AIC


```{r}
#Train-test split
set.seed(42)
train_index <- createDataPartition(auto_mpg$mpg, p = 0.8, list = FALSE)  # 80-20 split
train_data <- auto_mpg[train_index, ]
test_data <- auto_mpg[-train_index, ]

test_data$mpg<-log(test_data$mpg)
```

```{r}
data_original<-train_data
```

```{r}
fit_multi1 <- lm(I(log(mpg))~weight+horsepower + cut_model_year,data = auto_mpg)#ottimo
fit_multi2 <- lm(I(log(mpg))~weight + cut_model_year,data = auto_mpg)#ni
fit_multi3 <- lm(I(log(mpg))~weight+displacement+cut_model_year ,data = auto_mpg)#bo
fit_multi4 <- lm(I(log(mpg))~weight,data = auto_mpg)#bo

summary(fit_multi1)
summary(fit_multi2)
summary(fit_multi3)
summary(fit_multi4)

# plot(compare_performance(fit_multi1, fit_multi2, fit_multi3, fit_multi4))
```



##generate MAR

```{r create mv, echo=FALSE}
missingMar<-delete_MAR_1_to_x(data_original, p = 0.2, cols_mis = "weight", cols_ctrl ="displacement", x =100)
missingMar<-delete_MAR_censoring(missingMar, p = 0.1, cols_mis = "weight", cols_ctrl = "acceleration")

#plot VIM
aggr_plot <- aggr(missingMar, numbers = TRUE,labels=names(data_original), prop = c(TRUE, FALSE) )


#plot 2
missing.rows = dim(missingMar)[1] -  dim(na.omit(missingMar))[1]
#sprintf("Dim dataset: [%s]", toString(dim(missingMar)))
sprintf("Missing rows: %s (%s%%)", missing.rows, round((missing.rows*100)/dim(missingMar)[1], 2))

missings_df <- data.frame(type=c("missing", "non-missing") ,count = c(missing.rows,  dim(na.omit(missingMar))[1]))

ggplot(missings_df, aes(fill=type, y="", x=count)) + 
    geom_bar(position="stack", stat="identity")+
    ggtitle("%missing data") +
    xlab("Obs") + ylab("") +
    theme(text = element_text(size = 18))+
    scale_fill_manual(values = c(nord_colors[2], nord_colors[3]))+
    theme_bw()
``` 

## plot mv

```{r plot mv, warning=FALSE, echo=FALSE}
# Calculate global ranges for both x and y variables
dis_range <- range(c(data_original$displacement, missingMar$displacement), na.rm = TRUE)
weight_range <- range(c(data_original$weight, missingMar$weight), na.rm = TRUE)
accel_range <- range(c(data_original$acceleration, missingMar$acceleration), na.rm = TRUE)

# Add padding to ranges
dis_pad <- diff(dis_range) * 0.05
weight_pad <- diff(weight_range) * 0.05
accel_pad <- diff(accel_range) * 0.05

# First plot: DIS vs. Weight

plot_data1 <- data_original[, c("weight", "displacement")]
plot_data1$missing <- ifelse(is.na(missingMar$weight), "Missing", "Present")

scatter_plot1 <- ggplot(plot_data1, aes(x = weight, y = displacement, color = missing)) +
  geom_point(size = 2) +  # Increased point size
  scale_color_manual(values = c("Missing" = red_nord, "Present" = "black")) +  # Corrected color mapping
  scale_y_continuous(limits = c(dis_range[1] - dis_pad, dis_range[2] + dis_pad)) +
  scale_x_continuous(limits = c(weight_range[1] - weight_pad, weight_range[2] + weight_pad)) +
  theme_minimal(base_size = 12) +  # Increased base font size
  labs(color = "Data Status", x = "Weight", y = "Displacement") +
  theme(legend.position = "none")

final_plot1 <- ggMarginal(scatter_plot1, 
                          margins = "y", 
                          groupColour = TRUE, 
                          groupFill = TRUE,
                          type = "boxplot", 
                          size = 5,  
                          width = 0.2,  
                          outlier.size = 1)

# Second plot: Acceleration vs. Weight

plot_data2 <- data_original[, c("weight", "acceleration")]
plot_data2$missing <- ifelse(is.na(missingMar$weight), "Missing", "Present")

scatter_plot2 <- ggplot(plot_data2, aes(x = weight, y = acceleration, color = missing)) +
  geom_point(size = 2) +  
  scale_color_manual(values = c("Missing" = red_nord, "Present" = "black")) +  
  scale_y_continuous(limits = c(accel_range[1] - accel_pad, accel_range[2] + accel_pad)) +
  scale_x_continuous(limits = c(weight_range[1] - weight_pad, weight_range[2] + weight_pad)) +
  theme_minimal(base_size = 12) +  
  labs(color = "Data Status", x = "Weight", y = "Acceleration") +
  theme(legend.position = "none")

final_plot2 <- ggMarginal(scatter_plot2, 
                          margins = "y", 
                          groupColour = TRUE, 
                          groupFill = TRUE,
                          type = "boxplot", 
                          size = 5,  
                          width = 0.2,  
                          outlier.size = 1)

# Combine the two plots using gridExtra::grid.arrange()
grid.arrange(final_plot1, final_plot2, ncol=1)
```

### 3D Plot to showcase the relation better

```{r, fig.width=9, fig.height=9}

# Assuming `data_original` is your original dataset and `missingMar` is the modified one
plotMar_data <- data_original %>%
  mutate(missing = ifelse(is.na(missingMar$weight), "Missing", "Present"))  # Flag missing/present

# Create the 3D plot based on `plotMar_data`
plot_ly(data = plotMar_data, 
        x = ~displacement, 
        y = ~acceleration, 
        z = ~weight,  # Use original weight for z-axis
        color = ~missing, 
        colors = c("Present" = "black", "Missing" = red_nord),  # Ensure 'red' is defined
        type = 'scatter3d', 
        mode = 'markers', 
        marker = list(size = 4)) %>%  # Adjust point size here
  plotly::layout(
    title = '3D Plot of Missing vs Present Data',
    scene = list(
      xaxis = list(title = 'Displacement'),
      yaxis = list(title = 'Acceleration'),
      zaxis = list(title = 'Weight')
    )
  )

```

# Imputations

## mean y median y list

```{r imp statistic, echo=FALSE}
imp_ds_mean<-impute_mean(missingMar)
imp_ds_median<-impute_median(missingMar)
imp_del_list<-listwise_deletion(missingMar)
imp_ds_reg <- regression_imputation(missingMar[, -which(names(missingMar) == "car_brand")], noise = TRUE)
imp_ds_rf <- tree_based_imputation(missingMar[, -which(names(missingMar) == "car_brand")], noise = TRUE)

# Exclude the specified columns
prova <- missingMar[, !names(missingMar) %in% c("car_brand", "origin", "cylinders", "cut_model_year")]

# Perform imputation
imp_ds_gam <- gam_based_imputation(prova, noise = TRUE, max_predictors = 4)

# Combine the imputed dataset with the excluded columns
imp_ds_gam <- cbind(imp_ds_gam, missingMar[, c("car_brand", "origin", "cylinders", "cut_model_year")])

```
# fit
```{r imp statistic model, echo=FALSE}
fit_mean<-lm(I(log(mpg))~weight+horsepower + cut_model_year, data = imp_ds_mean)
fit_median<-lm(I(log(mpg))~weight+horsepower + cut_model_year, data = imp_ds_median)
fit_list<-lm(I(log(mpg))~weight+horsepower + cut_model_year, data = imp_del_list)
fit_reg<-lm(I(log(mpg))~weight+horsepower + cut_model_year, data = imp_ds_reg)
fit_rf<-lm(I(log(mpg))~weight+horsepower + cut_model_year, data = imp_ds_rf)
fit_gam<-lm(I(log(mpg))~weight+horsepower + cut_model_year, data = imp_ds_gam)
```

# summ
```{r imp summary fit, echo=FALSE}
summary(fit_mean)
summary(fit_median)
summary(fit_list)
summary(fit_reg)
summary(fit_rf)
summary(fit_gam)
```

# coefficient analysis

```{r}
# Extract coefficients and confidence intervals
fit_models <- list(mean = fit_mean, median = fit_median, list = fit_list, reg = fit_reg, rf = fit_rf, gam = fit_gam, or = fit_multi1)

# Create a data frame to store coefficients and their intervals
coef_df <- do.call(rbind, lapply(names(fit_models), function(model_name) {
  coefs <- summary(fit_models[[model_name]])$coefficients
  ci <- confint(fit_models[[model_name]])
  data.frame(
    Model = model_name,
    Term = rownames(coefs),
    Estimate = coefs[, "Estimate"],
    Lower_CI = ci[, 1],
    Upper_CI = ci[, 2]
  )
}))

# View the coefficient data frame
print(coef_df)

library(ggplot2)

# Plotting
ggplot(coef_df, aes(x = Term, y = Estimate, color = Model)) +
  geom_point(position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(ymin = Lower_CI, ymax = Upper_CI), width = 0.2, position = position_dodge(width = 0.5)) +
  labs(title = "Comparison of Coefficients with Confidence Intervals",
       x = "Terms",
       y = "Coefficient Estimate") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}
# Extract specific coefficients and their confidence intervals
coef_names <-"(Intercept)" # Specify the coefficients you want to compare

# Create a data frame to store selected coefficients and their intervals
selected_coef_df <- do.call(rbind, lapply(names(fit_models), function(model_name) {
  coefs <- summary(fit_models[[model_name]])$coefficients
  ci <- confint(fit_models[[model_name]])
  
  # Filter for selected coefficients
  selected_coefs <- coefs[coef_names, , drop = FALSE]
  selected_ci <- ci[coef_names, , drop = FALSE]
  
  data.frame(
    Model = model_name,
    Term = rownames(selected_coefs),
    Estimate = selected_coefs[, "Estimate"],
    Lower_CI = selected_ci[, 1],
    Upper_CI = selected_ci[, 2]
  )
}))

# View the selected coefficient data frame
print(selected_coef_df)


# Plotting selected coefficients with specified y-axis limits
ggplot(selected_coef_df, aes(x = Term, y = Estimate, color = Model)) +
  geom_point(position = position_dodge(width = 0.5), size = 3) +
  geom_errorbar(aes(ymin = Lower_CI, ymax = Upper_CI), width = 0.2, position = position_dodge(width = 0.5)) +
  labs(title = "Comparison of Selected Coefficients with Confidence Intervals",
       x = "Coefficient Terms",
       y = "Coefficient Estimate") +
  scale_y_continuous(limits = c(3.65, 4.05)) +  # Set y-axis limits
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```

# predictions

```{r}
#Predict on test data
pred_mean <- predict(fit_mean, newdata = test_data)
pred_median <- predict(fit_median, newdata = test_data)
pred_list <- predict(fit_list, newdata = test_data)
pred_reg <- predict(fit_reg, newdata = test_data)
pred_rf <- predict(fit_rf, newdata = test_data)
pred_gam <- predict(fit_gam, newdata = test_data)

pred_origin <- predict(fit_multi1, newdata = test_data)


rmse_value <- RMSE(pred_mean, test_data$mpg)
cat("mean (RMSE):", rmse_value, "\n")
rmse_value <- RMSE(pred_median, test_data$mpg)
cat("median (RMSE):", rmse_value, "\n")
rmse_value <- RMSE(pred_list, test_data$mpg)
cat("list del (RMSE):", rmse_value, "\n")
rmse_value <- RMSE(pred_reg, test_data$mpg)
cat("reg (RMSE):", rmse_value, "\n")
rmse_value <- RMSE(pred_rf, test_data$mpg)
cat("rf (RMSE):", rmse_value, "\n")
rmse_value <- RMSE(pred_gam, test_data$mpg)
cat("gam (RMSE):", rmse_value, "\n")


rmse_value <- RMSE(pred_origin, test_data$mpg)
cat("true (RMSE):", rmse_value, "\n")
```



# Cannone














# #######################
# work in progress
# #######################



*fare kcross-val*








##generate MAR


## plot fit
## guardare dens var ricostruite
## scatterplot con var ricostruite



## probabilmente così non va bene, split tt va fatto prima di generare i mar, come piano originale
